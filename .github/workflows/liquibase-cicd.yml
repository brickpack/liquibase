name: Liquibase CI/CD

on:
  push:
    branches-ignore: [main]
  pull_request:
    branches: [main]
    types: [synchronize, closed]
  workflow_dispatch:
    inputs:
      database:
        description: 'Database platform or specific database (mysql, postgresql, sqlserver, oracle, all, or exact name like mysql-ecommerce)'
        required: false
        default: 'all'
        type: string
      action:
        description: 'Action to perform'
        required: false
        default: 'auto'
        type: choice
        options:
        - auto
        - test
        - deploy

permissions:
  id-token: write
  contents: read

jobs:
  discover-databases:
    runs-on: ubuntu-latest
    outputs:
      databases: ${{ steps.filter.outputs.databases }}
      test-mode: ${{ steps.determine-mode.outputs.test-mode }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Discover all databases
      id: discover
      run: |
        databases=$(find . -name "changelog-*.xml" -type f | grep -v "changelog-bootstrap.xml" | sed 's|./changelog-||g' | sed 's|\.xml||g' | jq -R -s -c 'split("\n")[:-1]')
        echo "Found all databases: $databases"
        echo "all-databases=$databases" >> $GITHUB_OUTPUT

    - name: Filter databases by workflow dispatch input
      id: filter
      run: |
        ALL_DATABASES='${{ steps.discover.outputs.all-databases }}'
        DATABASE_INPUT="${{ github.event.inputs.database || 'all' }}"

        echo "Database input: $DATABASE_INPUT"
        echo "All databases: $ALL_DATABASES"

        if [[ "$DATABASE_INPUT" == "all" ]]; then
          echo "Running all databases"
          echo "databases=$ALL_DATABASES" >> $GITHUB_OUTPUT
        else
          # Convert input to lowercase for comparison
          DATABASE_INPUT_LOWER=$(echo "$DATABASE_INPUT" | tr '[:upper:]' '[:lower:]')

          # Filter databases using jq with platform matching
          FILTERED_DATABASES=$(echo "$ALL_DATABASES" | jq -c --arg input "$DATABASE_INPUT" --arg input_lower "$DATABASE_INPUT_LOWER" '
            map(select(
              if ($input_lower == "mysql" or $input_lower == "my-sql") then
                startswith("mysql-")
              elif ($input_lower == "postgresql" or $input_lower == "postgres" or $input_lower == "pg") then
                startswith("postgres-")
              elif ($input_lower == "sqlserver" or $input_lower == "sql-server" or $input_lower == "mssql") then
                startswith("sqlserver-")
              elif ($input_lower == "oracle" or $input_lower == "ora") then
                startswith("oracle-")
              else
                . == $input
              end
            ))
          ')

          echo "Filtered databases: $FILTERED_DATABASES"
          echo "databases=$FILTERED_DATABASES" >> $GITHUB_OUTPUT

          # Show which databases will run
          FILTERED_COUNT=$(echo "$FILTERED_DATABASES" | jq 'length')
          if [[ "$FILTERED_COUNT" == "0" ]]; then
            echo "⚠️ No databases match the filter '$DATABASE_INPUT'"
            echo "Available databases: $(echo "$ALL_DATABASES" | jq -r '.[]' | tr '\n' ' ')"
          else
            echo "✅ Selected databases: $(echo "$FILTERED_DATABASES" | jq -r '.[]' | tr '\n' ' ')"
          fi
        fi

    - name: Determine execution mode
      id: determine-mode
      run: |
        echo "Event details:"
        echo "   Event name: ${{ github.event_name }}"
        echo "   Action: ${{ github.event.action }}"
        echo "   PR merged: ${{ github.event.pull_request.merged }}"
        echo "   Base ref: ${{ github.event.pull_request.base.ref }}"
        echo "   Head ref: ${{ github.event.pull_request.head.ref }}"
        echo ""

        if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          if [[ "${{ github.event.inputs.action }}" == "test" ]]; then
            echo "Manual test mode requested"
            echo "test-mode=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event.inputs.action }}" == "deploy" ]]; then
            echo "Manual deploy mode requested"
            echo "test-mode=false" >> $GITHUB_OUTPUT
          else
            # Auto mode - never deploy in manual auto mode, always test
            echo "Manual auto mode - running tests only"
            echo "test-mode=true" >> $GITHUB_OUTPUT
          fi
        elif [[ "${{ github.event_name }}" == "pull_request" && "${{ github.event.action }}" == "closed" && "${{ github.event.pull_request.merged }}" == "true" && "${{ github.event.pull_request.base.ref }}" == "main" ]]; then
          echo "PR merged to main - running DEPLOYMENT"
          echo "test-mode=false" >> $GITHUB_OUTPUT
        else
          echo "Branch push or PR opened/updated - running TESTS only"
          echo "test-mode=true" >> $GITHUB_OUTPUT
        fi

  liquibase:
    needs: discover-databases
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository }}/liquibase-tools:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    strategy:
      matrix:
        database: ${{ fromJson(needs.discover-databases.outputs.databases) }}
      fail-fast: false

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      if: needs.discover-databases.outputs.test-mode == 'false'
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ vars.AWS_ROLE_ARN }}
        aws-region: ${{ vars.AWS_REGION || 'us-east-1' }}

    # Note: Java, Liquibase, and all database tools are pre-installed in the Docker image
    # No need to set up Java or install Liquibase - they're already available

    - name: Analyze changelog structure
      run: ./.github/scripts/analyze-changelog.sh ${{ matrix.database }}

    - name: Validate SQL syntax
      run: |
        echo "Validating SQL syntax for ${{ matrix.database }}..."

        # Find all SQL files referenced by this changelog
        SQL_FILES=$(grep -o 'file="[^"]*\.sql"' changelog-${{ matrix.database }}.xml | sed 's/file="//g' | sed 's/"//g')

        if [ -z "$SQL_FILES" ]; then
          echo "No SQL files found to validate"
          exit 0
        fi

        echo "📄 Found SQL files to validate:"
        echo "$SQL_FILES"
        echo ""

        # Check each SQL file for basic syntax issues
        VALIDATION_ERRORS=0

        for sql_file in $SQL_FILES; do
          if [ ! -f "$sql_file" ]; then
            echo "❌ File not found: $sql_file"
            VALIDATION_ERRORS=$((VALIDATION_ERRORS + 1))
            continue
          fi

          echo "Validating: $sql_file"

          # Check for common SQL syntax issues
          # 1. Check for unterminated quotes
          quote_error=0
          grep -n "'\|\"" "$sql_file" | grep -v "^[[:space:]]*--" | while read -r line; do
            line_num=$(echo "$line" | cut -d: -f1)
            content=$(echo "$line" | cut -d: -f2-)

            # Count single quotes (ignoring comments)
            single_quotes=$(echo "$content" | grep -o "'" | wc -l)
            if [ $((single_quotes % 2)) -ne 0 ]; then
              echo "⚠️  Line $line_num: Possible unterminated single quote"
              echo "1" > /tmp/quote_error_$$.tmp
            fi
          done
          
          if [ -f "/tmp/quote_error_$$.tmp" ]; then
            echo "❌ Quote validation failed for $sql_file"
            VALIDATION_ERRORS=$((VALIDATION_ERRORS + 1))
            rm -f /tmp/quote_error_$$.tmp
          fi

          # 2. Check for dollar quote issues
          # Extract all dollar quote tags from the entire file
          dollar_tags=$(grep -o '\$[^$]*\$' "$sql_file" | sort | uniq -c)

          # Check if each tag appears an even number of times
          dollar_quote_error=0
          echo "$dollar_tags" | while read -r count tag; do
            if [ -n "$tag" ] && [ $((count % 2)) -ne 0 ]; then
              echo "⚠️  Unmatched dollar quote tag: $tag (appears $count times)"
              dollar_quote_error=1
            fi
          done
          
          if [ $dollar_quote_error -eq 1 ]; then
            echo "❌ Dollar quote validation failed for $sql_file"
            VALIDATION_ERRORS=$((VALIDATION_ERRORS + 1))
          fi

          # 3. Check for required Liquibase headers
          if ! grep -q "^--liquibase formatted sql" "$sql_file"; then
            echo "❌ Missing Liquibase header in $sql_file"
            VALIDATION_ERRORS=$((VALIDATION_ERRORS + 1))
          fi

          # 4. Check for changeset format
          if ! grep -q "^--changeset " "$sql_file"; then
            echo "❌ No changesets found in $sql_file"
            VALIDATION_ERRORS=$((VALIDATION_ERRORS + 1))
          fi

          # 5. Check for potentially dangerous operations
          DANGEROUS_OPS=$(grep -in "DROP\|DELETE\|TRUNCATE" "$sql_file" | grep -v "^[[:space:]]*--" || true)
          if [ -n "$DANGEROUS_OPS" ]; then
            echo "⚠️  Potentially dangerous operations found in $sql_file:"
            echo "$DANGEROUS_OPS"
            echo "   Please review these operations carefully"
          fi

          echo "✅ Basic validation passed for $sql_file"
        done

        if [ $VALIDATION_ERRORS -gt 0 ]; then
          echo ""
          echo "❌ SQL validation failed with $VALIDATION_ERRORS error(s)"
          echo "Please fix the syntax errors above before proceeding"
          exit 1
        else
          echo ""
          echo "✅ All SQL files passed basic syntax validation"
        fi

    - name: Liquibase offline validation
      run: |
        echo "Running Liquibase offline validation for ${{ matrix.database }}..."

        # Create temporary offline configuration for validation
        cat > liquibase-${{ matrix.database }}-validation.properties << 'EOF'
        changelogFile=changelog-${{ matrix.database }}.xml
        url=offline:postgresql
        driver=org.postgresql.Driver
        logLevel=INFO
        logFile=liquibase-${{ matrix.database }}-validation.log
        outputFile=liquibase-${{ matrix.database }}-validation-output.txt
        EOF

        # Run Liquibase validation in offline mode
        if liquibase --defaults-file=liquibase-${{ matrix.database }}-validation.properties validate; then
          echo "✅ Liquibase offline validation PASSED for ${{ matrix.database }}"
        else
          echo "❌ Liquibase offline validation FAILED for ${{ matrix.database }}"
          echo "📄 Validation log:"
          if [ -f "liquibase-${{ matrix.database }}-validation.log" ]; then
            cat "liquibase-${{ matrix.database }}-validation.log"
          fi
          exit 1
        fi

        # Generate SQL preview in offline mode to catch additional issues
        echo "📋 Generating SQL preview to validate changeset logic..."
        if liquibase --defaults-file=liquibase-${{ matrix.database }}-validation.properties update-sql > planned-changes-${{ matrix.database }}-validation.sql; then
          echo "✅ SQL generation succeeded"

          # Show a preview of what would be executed
          echo "📄 SQL Preview (first 20 lines):"
          head -20 planned-changes-${{ matrix.database }}-validation.sql | nl

          # Check for safety patterns
          SAFETY_CHECKS=0
          if grep -q "IF NOT EXISTS\|CREATE OR REPLACE\|preconditions onFail:MARK_RAN" planned-changes-${{ matrix.database }}-validation.sql; then
            echo "✅ Safety patterns detected (IF NOT EXISTS/CREATE OR REPLACE/preconditions)"
            SAFETY_CHECKS=$((SAFETY_CHECKS + 1))
          fi

          if ! grep -q "DROP TABLE\|DELETE FROM\|TRUNCATE" planned-changes-${{ matrix.database }}-validation.sql; then
            echo "✅ No destructive operations detected"
            SAFETY_CHECKS=$((SAFETY_CHECKS + 1))
          else
            echo "⚠️  Destructive operations detected - please review carefully"
          fi

          echo "🛡️  Safety checks passed: $SAFETY_CHECKS/2"
        else
          echo "❌ SQL generation failed"
          exit 1
        fi

        # Cleanup temporary files
        rm -f liquibase-${{ matrix.database }}-validation.properties
        rm -f liquibase-${{ matrix.database }}-validation.log
        rm -f liquibase-${{ matrix.database }}-validation-output.txt
        rm -f planned-changes-${{ matrix.database }}-validation.sql

    - name: Configure database connection
      run: |
        ./.github/scripts/configure-database.sh \
          ${{ matrix.database }} \
          ${{ vars.SECRET_NAME || 'liquibase-databases' }} \
          ${{ needs.discover-databases.outputs.test-mode }}

    - name: Create database if needed
      if: needs.discover-databases.outputs.test-mode == 'false'
      run: |
        echo "Ensuring database exists for ${{ matrix.database }}..."

        # Extract database type and name from the configuration
        DB_TYPE=$(grep -E "^url=" liquibase-${{ matrix.database }}.properties | sed 's/url=jdbc://' | cut -d: -f1)

        # Extract database name based on database type
        DB_URL=$(grep -E "^url=" liquibase-${{ matrix.database }}.properties | sed 's/url=//')
        if [ "$DB_TYPE" = "sqlserver" ]; then
          # SQL Server uses databaseName= parameter
          DB_NAME=$(echo "$DB_URL" | sed -n 's/.*databaseName=\([^;]*\).*/\1/p')
        else
          # PostgreSQL, MySQL use /database format
          DB_NAME=$(echo "$DB_URL" | sed 's/.*\///' | sed 's/;.*//' | sed 's/?.*//')
        fi

        # Only create database in deploy mode (not test mode)
        SECRET_NAME="${{ vars.SECRET_NAME || 'liquibase-databases' }}"

        echo "Creating database: $DB_NAME (type: $DB_TYPE)"

        if [ "$DB_TYPE" = "postgresql" ]; then
          if ! ./.github/scripts/create-database.sh postgresql "$DB_NAME" "$SECRET_NAME"; then
            echo "❌ Failed to create PostgreSQL database: $DB_NAME"
            exit 1
          fi
        elif [ "$DB_TYPE" = "mysql" ]; then
          if ! ./.github/scripts/create-database.sh mysql "$DB_NAME" "$SECRET_NAME"; then
            echo "❌ Failed to create MySQL database: $DB_NAME"
            exit 1
          fi
        elif [ "$DB_TYPE" = "sqlserver" ]; then
          echo "⚡ Skipping SQL Server database creation (minimal setup mode)"
          echo "Assuming SQL Server database '$DB_NAME' already exists"
          echo "If database doesn't exist, Liquibase will show connection errors"
        elif [ "$DB_TYPE" = "oracle" ]; then
          if ! ./.github/scripts/create-database.sh oracle "$DB_NAME" "$SECRET_NAME"; then
            echo "❌ Failed to create Oracle database: $DB_NAME"
            exit 1
          fi
        else
          echo "Unknown database type: $DB_TYPE - skipping database creation"
        fi

        echo "✅ Database creation completed for: $DB_NAME"

    - name: Manage database users
      if: needs.discover-databases.outputs.test-mode == 'false'
      run: |
        echo "Managing database users for ${{ matrix.database }}..."

        # Set passwords from AWS Secrets Manager after Liquibase creates users
        # This runs after schema deployment to ensure users exist
        USER_SECRET_NAME="${{ vars.USER_SECRET_NAME || 'liquibase-users' }}"

        # Note: This step will run after Liquibase update to set real passwords
        # Liquibase creates users with temporary passwords, this sets the real ones
        echo "User password management will run after schema deployment"

    - name: Validate changelog
      run: |
        if ! ./.github/scripts/run-liquibase.sh ${{ matrix.database }} validate; then
          echo "Validation failed, likely due to checksum mismatch. Clearing checksums..."
          ./.github/scripts/run-liquibase.sh ${{ matrix.database }} clear-checksums
          echo "✅ Checksums cleared. Re-running validation..."
          ./.github/scripts/run-liquibase.sh ${{ matrix.database }} validate
        fi

    - name: Run deployment or generate test SQL
      run: |
        if [ "${{ needs.discover-databases.outputs.test-mode }}" = "true" ]; then
          echo "Running in TEST mode (branch push or PR validation)"
          echo "📋 This will validate changesets and generate SQL without making database changes"
          ./.github/scripts/run-liquibase.sh ${{ matrix.database }} update-sql true

          echo ""
          echo "🎯 TEST SUMMARY for ${{ matrix.database }}:"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "✅ Changelog validation: PASSED"
          echo "✅ SQL generation: COMPLETED"
          echo "📁 Artifacts will be uploaded for review"
          echo "Ready for deployment when PR is merged to main branch"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        else
          echo "Running in DEPLOY mode (PR merged to main)"
          echo "This will create databases and execute changesets in production"
          ./.github/scripts/run-liquibase.sh ${{ matrix.database }} update
          ./.github/scripts/run-liquibase.sh ${{ matrix.database }} status
        fi

    - name: Set user passwords from AWS Secrets Manager
      if: needs.discover-databases.outputs.test-mode == 'false'
      run: |
        echo "Setting real passwords for database users..."
        USER_SECRET_NAME="${{ vars.USER_SECRET_NAME || 'liquibase-users' }}"

        chmod +x ./.github/scripts/manage-users.sh
        if ./.github/scripts/manage-users.sh ${{ matrix.database }} "$USER_SECRET_NAME"; then
          echo "✅ User passwords updated successfully"
        else
          echo "⚠️ User password management failed or no users to manage"
          echo "Users may still have temporary passwords"
        fi

    - name: Cleanup sensitive files
      if: always()
      run: ./.github/scripts/cleanup.sh ${{ matrix.database }}

    - name: Show workflow status
      if: always()
      run: |
        if [ "${{ job.status }}" = "success" ]; then
          echo "Workflow completed successfully for ${{ matrix.database }}"
        else
          echo "❌ Workflow failed for ${{ matrix.database }}"
          echo "Check the logs above for error details"
        fi

    - name: Upload test results
      if: needs.discover-databases.outputs.test-mode == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.database }}
        path: |
          planned-changes-${{ matrix.database }}.sql
          liquibase-${{ matrix.database }}.log

    - name: Upload deployment artifacts
      if: needs.discover-databases.outputs.test-mode == 'false'
      uses: actions/upload-artifact@v4
      with:
        name: deployment-results-${{ matrix.database }}
        path: |
          planned-changes-${{ matrix.database }}.sql
          liquibase-${{ matrix.database }}.log
          liquibase-${{ matrix.database }}-output.txt

    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: failure-logs-${{ matrix.database }}
        path: |
          liquibase-${{ matrix.database }}.log
          liquibase-${{ matrix.database }}-output.txt